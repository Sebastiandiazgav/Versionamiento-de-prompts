# üöÄ Tutorial: Gesti√≥n de Prompts con PromptLayer y OpenAI/Ollama

Este tutorial te guiar√° paso a paso para crear un entorno de trabajo con PromptLayer, OpenAI y Ollama. Aprender√°s a gestionar versiones de prompts, etiquetar solicitudes y visualizar resultados en el dashboard de PromptLayer.

---

## üß± Paso 1: Activaci√≥n del Entorno Virtual

### En Windows (usando Git Bash)
```bash
source venv/Scripts/activate
```

### En macOS o Linux
```bash
source venv/bin/activate
```

Una vez activado, ver√°s `(venv)` al principio de la l√≠nea de tu terminal.

---

## üì¶ Paso 2: Instalaci√≥n de Dependencias

Con el entorno virtual activo, instala las siguientes librer√≠as necesarias:

```bash
pip install promptlayer openai
```

---

## üîê Paso 3: Configuraci√≥n de Claves de API

### 1. Obtener tu Clave de PromptLayer
- Ve a [promptlayer.com](https://promptlayer.com)
- Inicia sesi√≥n o reg√≠strate
- Copia tu clave desde la secci√≥n **Settings ‚öôÔ∏è**

### 2. Establecer las Variables de Entorno
Ejecuta estos comandos en tu terminal:

```bash
export PROMPTLAYER_API_KEY="pl_tu_clave_de_api_aqui"
export OPENAI_API_KEY="sk_tu_clave_de_openai_aqui"
```

> ‚ÑπÔ∏è **Nota**: La clave de OpenAI es requerida por la estructura de la librer√≠a, aunque las solicitudes se redirijan a Ollama.

---

## üß™ Paso 4: Crear Script - Versi√≥n 1

### 1. Crear el Archivo
```bash
touch run_v1.py
```

### 2. Contenido del Script

```python
# Archivo: run_v1.py
from openai import OpenAI
from promptlayer import PromptLayer

# --- Configuraci√≥n ---
promptlayer_client = PromptLayer()
client = promptlayer_client.openai.OpenAI(
    base_url='http://localhost:11434/v1',
    api_key='ollama',
)
# --------------------

print("Ejecutando Versi√≥n 1...")
response = client.chat.completions.create(
    model="llama3",
    messages=[
        {"role": "user", "content": "Comp√≥n un haiku sobre la programaci√≥n local."}
    ],
    pl_tags=["experimento-ollama-v1"]
)

print("\n--- Respuesta de V1 ---")
print(response.choices[0].message.content)
print("\nSolicitud V1 registrada en PromptLayer.")
```

### 3. Ejecutar el Script
```bash
python run_v1.py
```

---

## üß™ Paso 5: Crear Script - Versi√≥n 2

### 1. Crear el Archivo
```bash
touch run_v2.py
```

### 2. Contenido del Script

```python
# Archivo: run_v2.py
from openai import OpenAI
from promptlayer import PromptLayer

# --- Configuraci√≥n ---
promptlayer_client = PromptLayer()
client = promptlayer_client.openai.OpenAI(
    base_url='http://localhost:11434/v1',
    api_key='ollama',
)
# --------------------

print("Ejecutando Versi√≥n 2...")
response = client.chat.completions.create(
    model="llama3",
    messages=[
        {"role": "user", "content": "Escribe un chiste corto de dos l√≠neas sobre la programaci√≥n."}
    ],
    pl_tags=["experimento-ollama-v2"]
)

print("\n--- Respuesta de V2 ---")
print(response.choices[0].message.content)
print("\nSolicitud V2 registrada en PromptLayer.")
```

### 3. Ejecutar el Script
```bash
python run_v2.py
```

---

## üìä Paso 6: Verificaci√≥n en el Dashboard de PromptLayer

1. Abre tu navegador y entra a [PromptLayer](https://promptlayer.com)
2. Ve a la secci√≥n **Requests** desde el men√∫ lateral
3. Filtra por etiqueta:
    - `experimento-ollama-v1` ‚Üí Resultado del haiku
    - `experimento-ollama-v2` ‚Üí Resultado del chiste

---

## ‚úÖ Resultado Final

- ‚úÖ Se cre√≥ un entorno virtual y se instalaron dependencias
- ‚úÖ Se configuraron las claves necesarias
- ‚úÖ Se desarrollaron y ejecutaron dos scripts versionados
- ‚úÖ Se visualiz√≥ y verific√≥ cada versi√≥n en PromptLayer

